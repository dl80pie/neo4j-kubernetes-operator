/*
Copyright 2025.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
	"context"
	"fmt"
	goruntime "runtime"
	"strconv"
	"strings"
	"sync"
	"time"

	appsv1 "k8s.io/api/apps/v1"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/errors"
	"k8s.io/apimachinery/pkg/api/meta"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/client-go/tools/record"
	"k8s.io/client-go/util/workqueue"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/controller"
	"sigs.k8s.io/controller-runtime/pkg/controller/controllerutil"
	"sigs.k8s.io/controller-runtime/pkg/handler"
	"sigs.k8s.io/controller-runtime/pkg/log"
	"sigs.k8s.io/controller-runtime/pkg/reconcile"
	"sigs.k8s.io/controller-runtime/pkg/source"

	// Cert-manager types

	neo4jv1alpha1 "github.com/neo4j-labs/neo4j-operator/api/v1alpha1"
	"github.com/neo4j-labs/neo4j-operator/internal/metrics"
	neo4jclient "github.com/neo4j-labs/neo4j-operator/internal/neo4j"
	"github.com/neo4j-labs/neo4j-operator/internal/resources"
)

// Neo4jEnterpriseClusterReconciler reconciles a Neo4jEnterpriseCluster object with optimized memory usage
type Neo4jEnterpriseClusterReconciler struct {
	client.Client
	Scheme                  *runtime.Scheme
	Recorder                record.EventRecorder
	AdminSecret             string
	MaxConcurrentReconciles int
	RequeueAfter            time.Duration

	// Metrics collection
	ReconcileMetrics *metrics.ReconcileMetrics
	ClusterMetrics   *metrics.ClusterMetrics
	UpgradeMetrics   *metrics.UpgradeMetrics

	// Security coordinator for ordered reconciliation
	SecurityCoordinator *SecurityCoordinator

	// Resource pool for object reuse
	resourcePool *ResourcePool

	// Connection manager for Neo4j clients
	connectionManager *ConnectionManager
}

// ResourcePool manages reusable objects to reduce GC pressure
type ResourcePool struct {
	statefulSetPool sync.Pool
	configMapPool   sync.Pool
	servicePool     sync.Pool
	secretPool      sync.Pool
}

// ConnectionManager manages Neo4j client connections with caching
type ConnectionManager struct {
	clients map[string]*neo4jclient.Client
	mutex   sync.RWMutex

	// Connection cleanup
	lastCleanup     time.Time
	cleanupInterval time.Duration
}

// NewResourcePool creates a new resource pool for memory efficiency
func NewResourcePool() *ResourcePool {
	return &ResourcePool{
		statefulSetPool: sync.Pool{
			New: func() interface{} {
				return &appsv1.StatefulSet{}
			},
		},
		configMapPool: sync.Pool{
			New: func() interface{} {
				return &corev1.ConfigMap{}
			},
		},
		servicePool: sync.Pool{
			New: func() interface{} {
				return &corev1.Service{}
			},
		},
		secretPool: sync.Pool{
			New: func() interface{} {
				return &corev1.Secret{}
			},
		},
	}
}

// NewConnectionManager creates a new connection manager
func NewConnectionManager() *ConnectionManager {
	return &ConnectionManager{
		clients:         make(map[string]*neo4jclient.Client),
		cleanupInterval: 5 * time.Minute,
		lastCleanup:     time.Now(),
	}
}

// GetStatefulSet gets a StatefulSet from the pool
func (p *ResourcePool) GetStatefulSet() *appsv1.StatefulSet {
	return p.statefulSetPool.Get().(*appsv1.StatefulSet)
}

// PutStatefulSet returns a StatefulSet to the pool
func (p *ResourcePool) PutStatefulSet(sts *appsv1.StatefulSet) {
	// Reset the object
	*sts = appsv1.StatefulSet{}
	p.statefulSetPool.Put(sts)
}

// GetConfigMap gets a ConfigMap from the pool
func (p *ResourcePool) GetConfigMap() *corev1.ConfigMap {
	return p.configMapPool.Get().(*corev1.ConfigMap)
}

// PutConfigMap returns a ConfigMap to the pool
func (p *ResourcePool) PutConfigMap(cm *corev1.ConfigMap) {
	*cm = corev1.ConfigMap{}
	p.configMapPool.Put(cm)
}

// GetService gets a Service from the pool
func (p *ResourcePool) GetService() *corev1.Service {
	return p.servicePool.Get().(*corev1.Service)
}

// PutService returns a Service to the pool
func (p *ResourcePool) PutService(svc *corev1.Service) {
	*svc = corev1.Service{}
	p.servicePool.Put(svc)
}

// GetSecret gets a Secret from the pool
func (p *ResourcePool) GetSecret() *corev1.Secret {
	return p.secretPool.Get().(*corev1.Secret)
}

// PutSecret returns a Secret to the pool
func (p *ResourcePool) PutSecret(secret *corev1.Secret) {
	*secret = corev1.Secret{}
	p.secretPool.Put(secret)
}

// GetClient gets or creates a Neo4j client with caching
func (cm *ConnectionManager) GetClient(cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, k8sClient client.Client) (*neo4jclient.Client, error) {
	key := fmt.Sprintf("%s/%s", cluster.Namespace, cluster.Name)

	cm.mutex.RLock()
	if client, exists := cm.clients[key]; exists {
		cm.mutex.RUnlock()
		return client, nil
	}
	cm.mutex.RUnlock()

	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	// Double-check after acquiring write lock
	if client, exists := cm.clients[key]; exists {
		return client, nil
	}

	// Create new client
	adminSecretName := fmt.Sprintf("%s-admin", cluster.Name)
	client, err := neo4jclient.NewClientForEnterprise(cluster, k8sClient, adminSecretName)
	if err != nil {
		return nil, err
	}

	cm.clients[key] = client

	// Cleanup old connections if needed
	if time.Since(cm.lastCleanup) > cm.cleanupInterval {
		go cm.cleanupOldConnections()
		cm.lastCleanup = time.Now()
	}

	return client, nil
}

// cleanupOldConnections removes unused client connections
func (cm *ConnectionManager) cleanupOldConnections() {
	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	// Simple cleanup - in production, you'd want more sophisticated logic
	for key, client := range cm.clients {
		// Check if connection is still healthy
		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		err := client.VerifyConnectivity(ctx)
		cancel()

		if err != nil {
			client.Close()
			delete(cm.clients, key)
		}
	}
}

// CloseAll closes all client connections
func (cm *ConnectionManager) CloseAll() {
	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	for _, client := range cm.clients {
		client.Close()
	}
	cm.clients = make(map[string]*neo4jclient.Client)
}

// +kubebuilder:rbac:groups=neo4j.neo4j.com,resources=neo4jenterpriseclusters,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=neo4j.neo4j.com,resources=neo4jenterpriseclusters/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=neo4j.neo4j.com,resources=neo4jenterpriseclusters/finalizers,verbs=update
// +kubebuilder:rbac:groups=apps,resources=statefulsets,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups="",resources=services,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups="",resources=secrets,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups="",resources=configmaps,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups="",resources=serviceaccounts,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups="",resources=persistentvolumeclaims,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=networking.k8s.io,resources=ingresses,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=cert-manager.io,resources=certificates,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups="",resources=events,verbs=create;patch

// Reconcile is the main reconciliation logic with optimized memory usage
func (r *Neo4jEnterpriseClusterReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
	// Start metrics collection with context
	reconcileStart := time.Now()
	defer func() {
		r.ReconcileMetrics.ReconcileDuration.Observe(time.Since(reconcileStart).Seconds())

		// Force garbage collection every 10 reconciles to manage memory
		if r.ReconcileMetrics.GetReconcileCount()%10 == 0 {
			goruntime.GC()
		}
	}()

	logger := log.FromContext(ctx).WithValues("enterprisecluster", req.NamespacedName)
	logger.Info("Starting reconciliation")

	// Fetch the Neo4jEnterpriseCluster instance with retry
	cluster := &neo4jv1alpha1.Neo4jEnterpriseCluster{}
	err := r.Get(ctx, req.NamespacedName, cluster)
	if err != nil {
		if errors.IsNotFound(err) {
			logger.Info("Neo4jEnterpriseCluster resource not found. Ignoring since object must be deleted")
			return ctrl.Result{}, nil
		}
		logger.Error(err, "Failed to get Neo4jEnterpriseCluster")
		r.ReconcileMetrics.ReconcileErrors.Inc()
		return ctrl.Result{RequeueAfter: 30 * time.Second}, err
	}

	// Handle deletion with proper cleanup
	if !cluster.ObjectMeta.DeletionTimestamp.IsZero() {
		return r.handleDeletion(ctx, cluster)
	}

	// Add finalizer if not present
	if !controllerutil.ContainsFinalizer(cluster, "neo4j.neo4j.com/finalizer") {
		controllerutil.AddFinalizer(cluster, "neo4j.neo4j.com/finalizer")
		if err := r.Update(ctx, cluster); err != nil {
			logger.Error(err, "Failed to add finalizer")
			return ctrl.Result{RequeueAfter: 5 * time.Second}, err
		}
		return ctrl.Result{Requeue: true}, nil
	}

	// Wait for security resources if needed
	if r.SecurityCoordinator != nil {
		if err := r.SecurityCoordinator.WaitForSecurityResources(ctx, cluster.Namespace); err != nil {
			logger.Info("Waiting for security resources to be ready", "error", err)
			return ctrl.Result{RequeueAfter: 10 * time.Second}, nil
		}
	}

	// Main reconciliation logic with optimized resource management
	result, err := r.reconcileCluster(ctx, cluster)

	// Update metrics based on result
	if err != nil {
		r.ReconcileMetrics.ReconcileErrors.Inc()
	} else {
		r.ReconcileMetrics.ReconcileSuccess.Inc()
	}

	return result, err
}

// reconcileCluster handles the main cluster reconciliation with memory optimization
func (r *Neo4jEnterpriseClusterReconciler) reconcileCluster(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster) (ctrl.Result, error) {
	logger := log.FromContext(ctx)

	// Initialize status if empty
	if cluster.Status.Phase == "" {
		cluster.Status.Phase = "Initializing"
		cluster.Status.Conditions = []neo4jv1alpha1.ClusterCondition{
			{
				Type:               "Initializing",
				Status:             metav1.ConditionTrue,
				LastTransitionTime: metav1.Now(),
				Reason:             "ClusterStartup",
				Message:            "Cluster initialization started",
			},
		}
		if err := r.Status().Update(ctx, cluster); err != nil {
			return ctrl.Result{}, err
		}
	}

	// Create or update resources using object pools
	if err := r.createOrUpdateResources(ctx, cluster); err != nil {
		logger.Error(err, "Failed to create or update resources")
		return ctrl.Result{RequeueAfter: 30 * time.Second}, err
	}

	// Get the StatefulSet to check status
	sts := r.resourcePool.GetStatefulSet()
	defer r.resourcePool.PutStatefulSet(sts)

	if err := r.Get(ctx, types.NamespacedName{
		Name:      cluster.Name,
		Namespace: cluster.Namespace,
	}, sts); err != nil {
		if errors.IsNotFound(err) {
			logger.Info("StatefulSet not found, will be created in next iteration")
			return ctrl.Result{RequeueAfter: 5 * time.Second}, nil
		}
		return ctrl.Result{}, err
	}

	// Update cluster status based on StatefulSet
	if err := r.updateClusterStatus(ctx, cluster, sts); err != nil {
		logger.Error(err, "Failed to update cluster status")
		return ctrl.Result{RequeueAfter: 10 * time.Second}, err
	}

	// Handle upgrades if needed (only when cluster is ready)
	if cluster.Status.Phase == "Ready" {
		if upgradeResult, err := r.handleUpgrade(ctx, cluster); err != nil {
			logger.Error(err, "Failed to handle upgrade")
			return ctrl.Result{RequeueAfter: 60 * time.Second}, err
		} else if upgradeResult.Requeue || upgradeResult.RequeueAfter > 0 {
			return upgradeResult, nil
		}
	}

	// Collect cluster metrics
	r.collectClusterMetrics(cluster, sts)

	// Normal reconciliation complete
	logger.Info("Reconciliation completed successfully")
	return ctrl.Result{RequeueAfter: 5 * time.Minute}, nil
}

// createOrUpdateResources creates or updates all required resources using object pools
func (r *Neo4jEnterpriseClusterReconciler) createOrUpdateResources(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster) error {
	// Create or update ConfigMap
	if err := r.createOrUpdateConfigMap(ctx, cluster); err != nil {
		return fmt.Errorf("failed to create/update ConfigMap: %w", err)
	}

	// Create or update Service
	if err := r.createOrUpdateService(ctx, cluster); err != nil {
		return fmt.Errorf("failed to create/update Service: %w", err)
	}

	// Create or update admin Secret if not exists
	if err := r.createAdminSecretIfNotExists(ctx, cluster); err != nil {
		return fmt.Errorf("failed to create admin Secret: %w", err)
	}

	// Create or update StatefulSet
	if err := r.createOrUpdateStatefulSet(ctx, cluster); err != nil {
		return fmt.Errorf("failed to create/update StatefulSet: %w", err)
	}

	return nil
}

// collectClusterMetrics collects metrics for monitoring
func (r *Neo4jEnterpriseClusterReconciler) collectClusterMetrics(cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, sts *appsv1.StatefulSet) {
	if r.ClusterMetrics == nil {
		return
	}

	// Update cluster health metrics
	health := 0.0
	if cluster.Status.Phase == "Ready" {
		health = 1.0
	}
	r.ClusterMetrics.ClusterHealth.WithLabelValues(cluster.Namespace, cluster.Name).Set(health)

	// Update replica metrics
	if sts.Status.Replicas > 0 {
		readyRatio := float64(sts.Status.ReadyReplicas) / float64(sts.Status.Replicas)
		r.ClusterMetrics.ClusterReplicas.WithLabelValues(cluster.Namespace, cluster.Name, "ready").Set(float64(sts.Status.ReadyReplicas))
		r.ClusterMetrics.ClusterReplicas.WithLabelValues(cluster.Namespace, cluster.Name, "total").Set(float64(sts.Status.Replicas))
		r.ClusterMetrics.ClusterHealth.WithLabelValues(cluster.Namespace, cluster.Name+"_replica_ratio").Set(readyRatio)
	}
}

// SetupWithManager sets up the controller with the Manager with optimized settings
func (r *Neo4jEnterpriseClusterReconciler) SetupWithManager(mgr ctrl.Manager) error {
	// Initialize resource pool and connection manager
	r.resourcePool = NewResourcePool()
	r.connectionManager = NewConnectionManager()

	// Custom rate limiter for better performance
	rateLimiter := workqueue.NewMaxOfRateLimiter(
		workqueue.NewItemExponentialFailureRateLimiter(1*time.Second, 60*time.Second),
		&workqueue.BucketRateLimiter{Limiter: rateLimiter.NewLimiter(rateLimiter.Limit(10), 100)},
	)

	return ctrl.NewControllerManagedBy(mgr).
		For(&neo4jv1alpha1.Neo4jEnterpriseCluster{}).
		Owns(&appsv1.StatefulSet{}).
		Owns(&corev1.Service{}).
		Owns(&corev1.ConfigMap{}).
		Owns(&corev1.Secret{}).
		WithOptions(controller.Options{
			MaxConcurrentReconciles: 5, // Limit concurrent reconciliations for memory efficiency
			RateLimiter:             rateLimiter,
		}).
		Watches(
			&source.Kind{Type: &corev1.Pod{}},
			handler.EnqueueRequestsFromMapFunc(r.podToEnterpriseCluster),
		).
		Complete(r)
}

// podToEnterpriseCluster maps Pod events to Neo4jEnterpriseCluster reconcile requests
func (r *Neo4jEnterpriseClusterReconciler) podToEnterpriseCluster(obj client.Object) []reconcile.Request {
	pod, ok := obj.(*corev1.Pod)
	if !ok {
		return nil
	}

	// Only process pods with the appropriate labels
	if clusterName, exists := pod.Labels["app.kubernetes.io/name"]; exists &&
		pod.Labels["app.kubernetes.io/component"] == "neo4j" {
		return []reconcile.Request{
			{
				NamespacedName: types.NamespacedName{
					Name:      clusterName,
					Namespace: pod.Namespace,
				},
			},
		}
	}

	return nil
}

// handleDeletion handles cluster deletion with proper cleanup
func (r *Neo4jEnterpriseClusterReconciler) handleDeletion(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster) error {
	logger := log.FromContext(ctx)
	logger.Info("Handling Neo4jEnterpriseCluster deletion")

	// Perform any cleanup operations
	// This could include backup operations, graceful shutdown, etc.

	return nil
}

func (r *Neo4jEnterpriseClusterReconciler) updateClusterStatus(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, sts *appsv1.StatefulSet) error {
	// Update cluster status based on StatefulSet
	cluster.Status.Replicas = &neo4jv1alpha1.ReplicaStatus{
		Primaries: sts.Status.ReadyReplicas,
		Ready:     sts.Status.ReadyReplicas,
	}

	if cluster.Spec.Topology.Secondaries > 0 {
		secondarySts := &appsv1.StatefulSet{}
		if err := r.Get(ctx, types.NamespacedName{
			Name:      fmt.Sprintf("%s-secondary", cluster.Name),
			Namespace: cluster.Namespace,
		}, secondarySts); err != nil {
			return err
		}
		cluster.Status.Replicas.Secondaries = secondarySts.Status.ReadyReplicas
		cluster.Status.Replicas.Ready += secondarySts.Status.ReadyReplicas
	}

	// Update endpoints
	endpoints := &neo4jv1alpha1.EndpointStatus{
		Bolt: fmt.Sprintf("%s-client.%s.svc.cluster.local:7687", cluster.Name, cluster.Namespace),
		HTTP: fmt.Sprintf("%s-client.%s.svc.cluster.local:7474", cluster.Name, cluster.Namespace),
		Internal: &neo4jv1alpha1.InternalEndpoints{
			Headless: fmt.Sprintf("%s-headless.%s.svc.cluster.local", cluster.Name, cluster.Namespace),
			Client:   fmt.Sprintf("%s-client.%s.svc.cluster.local", cluster.Name, cluster.Namespace),
		},
	}

	if cluster.Spec.TLS != nil && cluster.Spec.TLS.Mode == "cert-manager" {
		endpoints.HTTPS = fmt.Sprintf("%s-client.%s.svc.cluster.local:7473", cluster.Name, cluster.Namespace)
	}

	// Connect to Neo4j and validate Enterprise version
	client, err := r.connectionManager.GetClient(cluster, r.Client)
	if err != nil {
		return fmt.Errorf("failed to create Neo4j client: %w", err)
	}
	defer client.Close()

	// Verify connectivity
	if err := client.VerifyConnectivity(ctx); err != nil {
		return fmt.Errorf("failed to verify Neo4j connectivity: %w", err)
	}

	// Validate Enterprise version 5.26+
	if err := client.ValidateEnterpriseVersion(ctx); err != nil {
		return fmt.Errorf("Neo4j version validation failed: %w", err)
	}

	// Update cluster status
	cluster.Status.Endpoints = endpoints
	cluster.Status.Version = cluster.Spec.Image.Tag

	return r.Status().Update(ctx, cluster)
}

func (r *Neo4jEnterpriseClusterReconciler) handleUpgrade(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster) (ctrl.Result, error) {
	logger := log.FromContext(ctx)
	logger.Info("Handling cluster upgrade", "from", cluster.Status.Version, "to", cluster.Spec.Image.Tag)

	// Set upgrade condition
	meta.SetStatusCondition(&cluster.Status.Conditions, metav1.Condition{
		Type:    "UpgradeInProgress",
		Status:  metav1.ConditionTrue,
		Reason:  "UpgradeStarted",
		Message: fmt.Sprintf("Upgrading from %s to %s", cluster.Status.Version, cluster.Spec.Image.Tag),
	})

	// Use Neo4j client to check if upgrade is safe
	client, err := r.connectionManager.GetClient(cluster, r.Client)
	if err != nil {
		return ctrl.Result{}, fmt.Errorf("failed to create Neo4j client: %w", err)
	}
	defer client.Close()

	// Comprehensive upgrade safety validation
	if err := client.ValidateUpgradeSafety(ctx, cluster.Spec.Image.Tag); err != nil {
		meta.SetStatusCondition(&cluster.Status.Conditions, metav1.Condition{
			Type:    "UpgradeInProgress",
			Status:  metav1.ConditionFalse,
			Reason:  "UpgradeFailed",
			Message: fmt.Sprintf("Upgrade safety validation failed: %v", err),
		})
		return ctrl.Result{}, fmt.Errorf("upgrade safety validation failed: %w", err)
	}

	// Phase 1: Upgrade secondaries first (if any)
	if cluster.Spec.Topology.Secondaries > 0 {
		logger.Info("Starting secondary upgrade phase")
		if err := r.upgradeSecondaries(ctx, cluster, client); err != nil {
			return ctrl.Result{}, fmt.Errorf("failed to upgrade secondaries: %w", err)
		}
		logger.Info("Secondary upgrade phase completed")
	}

	// Phase 2: Upgrade non-leader primaries
	logger.Info("Starting non-leader primary upgrade phase")
	if err := r.upgradeNonLeaderPrimaries(ctx, cluster, client); err != nil {
		return ctrl.Result{}, fmt.Errorf("failed to upgrade non-leader primaries: %w", err)
	}
	logger.Info("Non-leader primary upgrade phase completed")

	// Phase 3: Upgrade leader last
	logger.Info("Starting leader upgrade phase")
	if err := r.upgradeLeader(ctx, cluster, client); err != nil {
		return ctrl.Result{}, fmt.Errorf("failed to upgrade leader: %w", err)
	}
	logger.Info("Leader upgrade phase completed")

	// Final validation
	if err := client.WaitForClusterStabilization(ctx, 5*time.Minute); err != nil {
		return ctrl.Result{}, fmt.Errorf("cluster failed to stabilize after upgrade: %w", err)
	}

	// Update status
	cluster.Status.LastUpgradeTime = &metav1.Time{Time: time.Now()}
	meta.SetStatusCondition(&cluster.Status.Conditions, metav1.Condition{
		Type:    "UpgradeInProgress",
		Status:  metav1.ConditionFalse,
		Reason:  "UpgradeComplete",
		Message: "Upgrade completed successfully",
	})

	r.Recorder.Event(cluster, corev1.EventTypeNormal, "UpgradeComplete",
		fmt.Sprintf("Successfully upgraded from %s to %s", cluster.Status.Version, cluster.Spec.Image.Tag))

	return ctrl.Result{}, nil
}

func (r *Neo4jEnterpriseClusterReconciler) upgradeSecondaries(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, client *neo4jclient.Client) error {
	logger := log.FromContext(ctx)

	// Get secondary StatefulSet
	secondarySts := &appsv1.StatefulSet{}
	if err := r.Get(ctx, types.NamespacedName{
		Name:      fmt.Sprintf("%s-secondary", cluster.Name),
		Namespace: cluster.Namespace,
	}, secondarySts); err != nil {
		if errors.IsNotFound(err) {
			// No secondaries to upgrade
			return nil
		}
		return err
	}

	// Update image in StatefulSet
	newImage := fmt.Sprintf("%s:%s", cluster.Spec.Image.Repo, cluster.Spec.Image.Tag)
	if secondarySts.Spec.Template.Spec.Containers[0].Image == newImage {
		logger.Info("Secondary StatefulSet already has target image")
		return nil
	}

	logger.Info("Updating secondary StatefulSet image", "image", newImage)
	secondarySts.Spec.Template.Spec.Containers[0].Image = newImage

	// Add upgrade annotation to trigger rolling update
	if secondarySts.Spec.Template.Annotations == nil {
		secondarySts.Spec.Template.Annotations = make(map[string]string)
	}
	secondarySts.Spec.Template.Annotations["neo4j.com/upgrade-timestamp"] = time.Now().Format(time.RFC3339)

	if err := r.Update(ctx, secondarySts); err != nil {
		return fmt.Errorf("failed to update secondary StatefulSet: %w", err)
	}

	// Wait for rolling update to complete
	if err := r.waitForStatefulSetRollout(ctx, secondarySts, 10*time.Minute); err != nil {
		return fmt.Errorf("secondary StatefulSet rollout failed: %w", err)
	}

	// Verify secondaries are healthy and caught up
	if err := client.WaitForClusterStabilization(ctx, 3*time.Minute); err != nil {
		return fmt.Errorf("secondaries failed to stabilize: %w", err)
	}

	logger.Info("Secondary upgrade completed successfully")
	return nil
}

func (r *Neo4jEnterpriseClusterReconciler) upgradeNonLeaderPrimaries(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, client *neo4jclient.Client) error {
	logger := log.FromContext(ctx)

	// Get primary StatefulSet
	primarySts := &appsv1.StatefulSet{}
	if err := r.Get(ctx, types.NamespacedName{
		Name:      fmt.Sprintf("%s-primary", cluster.Name),
		Namespace: cluster.Namespace,
	}, primarySts); err != nil {
		return err
	}

	// Get current leader
	leader, err := client.GetLeader(ctx)
	if err != nil {
		return fmt.Errorf("failed to get current leader: %w", err)
	}

	// Get non-leader primaries
	nonLeaderPrimaries, err := client.GetNonLeaderPrimaries(ctx)
	if err != nil {
		return fmt.Errorf("failed to get non-leader primaries: %w", err)
	}

	logger.Info("Upgrading non-leader primaries", "count", len(nonLeaderPrimaries), "leader", leader.ID)

	// Update image in StatefulSet
	newImage := fmt.Sprintf("%s:%s", cluster.Spec.Image.Repo, cluster.Spec.Image.Tag)
	if primarySts.Spec.Template.Spec.Containers[0].Image == newImage {
		logger.Info("Primary StatefulSet already has target image")
		return nil
	}

	primarySts.Spec.Template.Spec.Containers[0].Image = newImage

	// Add upgrade annotation
	if primarySts.Spec.Template.Annotations == nil {
		primarySts.Spec.Template.Annotations = make(map[string]string)
	}
	primarySts.Spec.Template.Annotations["neo4j.com/upgrade-timestamp"] = time.Now().Format(time.RFC3339)

	// Use partition update to upgrade non-leader primaries first
	// Parse leader ordinal from ID (assuming format like cluster-primary-0)
	leaderOrdinal := r.extractOrdinalFromMemberID(leader.ID)
	if leaderOrdinal >= 0 {
		// Set partition to upgrade all pods except the leader
		partition := int32(leaderOrdinal)
		primarySts.Spec.UpdateStrategy.RollingUpdate = &appsv1.RollingUpdateStatefulSetStrategy{
			Partition: &partition,
		}
		logger.Info("Setting StatefulSet partition to preserve leader", "partition", partition, "leaderOrdinal", leaderOrdinal)
	}

	if err := r.Update(ctx, primarySts); err != nil {
		return fmt.Errorf("failed to update primary StatefulSet: %w", err)
	}

	// Wait for non-leader primaries to be upgraded
	if err := r.waitForPartialStatefulSetRollout(ctx, primarySts, leaderOrdinal, 10*time.Minute); err != nil {
		return fmt.Errorf("non-leader primary rollout failed: %w", err)
	}

	// Verify cluster stability after non-leader upgrade
	if err := client.WaitForClusterStabilization(ctx, 3*time.Minute); err != nil {
		return fmt.Errorf("cluster failed to stabilize after non-leader primary upgrade: %w", err)
	}

	logger.Info("Non-leader primary upgrade completed successfully")
	return nil
}

func (r *Neo4jEnterpriseClusterReconciler) upgradeLeader(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, client *neo4jclient.Client) error {
	logger := log.FromContext(ctx)

	// Get current leader before upgrade
	originalLeader, err := client.GetLeader(ctx)
	if err != nil {
		return fmt.Errorf("failed to get current leader: %w", err)
	}

	logger.Info("Upgrading leader", "leaderId", originalLeader.ID)

	// Get primary StatefulSet
	primarySts := &appsv1.StatefulSet{}
	if err := r.Get(ctx, types.NamespacedName{
		Name:      fmt.Sprintf("%s-primary", cluster.Name),
		Namespace: cluster.Namespace,
	}, primarySts); err != nil {
		return err
	}

	// Remove partition to allow leader upgrade
	primarySts.Spec.UpdateStrategy.RollingUpdate = &appsv1.RollingUpdateStatefulSetStrategy{
		Partition: nil,
	}

	if err := r.Update(ctx, primarySts); err != nil {
		return fmt.Errorf("failed to remove StatefulSet partition: %w", err)
	}

	// Wait for complete rollout including leader
	if err := r.waitForStatefulSetRollout(ctx, primarySts, 10*time.Minute); err != nil {
		return fmt.Errorf("leader rollout failed: %w", err)
	}

	// Wait for leader election to complete
	if err := r.waitForLeaderElection(ctx, client, originalLeader.ID, 5*time.Minute); err != nil {
		return fmt.Errorf("leader election failed after upgrade: %w", err)
	}

	// Final cluster stabilization
	if err := client.WaitForClusterStabilization(ctx, 3*time.Minute); err != nil {
		return fmt.Errorf("cluster failed to stabilize after leader upgrade: %w", err)
	}

	logger.Info("Leader upgrade completed successfully")
	return nil
}

// Helper methods for upgrade orchestration

func (r *Neo4jEnterpriseClusterReconciler) waitForStatefulSetRollout(ctx context.Context, sts *appsv1.StatefulSet, timeout time.Duration) error {
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return fmt.Errorf("timeout waiting for StatefulSet rollout")
		case <-ticker.C:
			current := &appsv1.StatefulSet{}
			if err := r.Get(ctx, types.NamespacedName{
				Name:      sts.Name,
				Namespace: sts.Namespace,
			}, current); err != nil {
				continue
			}

			// Check if rollout is complete
			if current.Status.ObservedGeneration >= current.Generation &&
				current.Status.ReadyReplicas == *current.Spec.Replicas &&
				current.Status.UpdatedReplicas == *current.Spec.Replicas {
				return nil
			}
		}
	}
}

func (r *Neo4jEnterpriseClusterReconciler) waitForPartialStatefulSetRollout(ctx context.Context, sts *appsv1.StatefulSet, preserveOrdinal int, timeout time.Duration) error {
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return fmt.Errorf("timeout waiting for partial StatefulSet rollout")
		case <-ticker.C:
			current := &appsv1.StatefulSet{}
			if err := r.Get(ctx, types.NamespacedName{
				Name:      sts.Name,
				Namespace: sts.Namespace,
			}, current); err != nil {
				continue
			}

			// For partition updates, we expect UpdatedReplicas to be total - partition
			expectedUpdated := *current.Spec.Replicas - int32(preserveOrdinal)
			if expectedUpdated <= 0 {
				expectedUpdated = *current.Spec.Replicas - 1 // At least upgrade all but one
			}

			if current.Status.ObservedGeneration >= current.Generation &&
				current.Status.ReadyReplicas == *current.Spec.Replicas &&
				current.Status.UpdatedReplicas >= expectedUpdated {
				return nil
			}
		}
	}
}

func (r *Neo4jEnterpriseClusterReconciler) waitForLeaderElection(ctx context.Context, client *neo4jclient.Client, originalLeaderID string, timeout time.Duration) error {
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	ticker := time.NewTicker(5 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return fmt.Errorf("timeout waiting for leader election")
		case <-ticker.C:
			// Check if we have a leader (could be same or different)
			leader, err := client.GetLeader(ctx)
			if err != nil {
				continue // Keep waiting
			}

			if leader != nil {
				// Leader election completed, verify cluster health
				healthy, err := client.IsClusterHealthy(ctx)
				if err != nil {
					continue
				}
				if healthy {
					return nil
				}
			}
		}
	}
}

func (r *Neo4jEnterpriseClusterReconciler) extractOrdinalFromMemberID(memberID string) int {
	// Extract ordinal from member ID (e.g., "cluster-primary-2" -> 2)
	parts := strings.Split(memberID, "-")
	if len(parts) > 0 {
		if ordinal, err := strconv.Atoi(parts[len(parts)-1]); err == nil {
			return ordinal
		}
	}
	return -1 // Could not extract ordinal
}

func (r *Neo4jEnterpriseClusterReconciler) createOrUpdateConfigMap(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster) error {
	configMap := resources.BuildConfigMapForEnterprise(cluster)

	found := &corev1.ConfigMap{}
	err := r.Get(ctx, types.NamespacedName{Name: configMap.Name, Namespace: configMap.Namespace}, found)
	if err != nil && errors.IsNotFound(err) {
		if err := ctrl.SetControllerReference(cluster, configMap, r.Scheme); err != nil {
			return err
		}
		return r.Create(ctx, configMap)
	} else if err != nil {
		return err
	}

	// Update ConfigMap if needed
	found.Data = configMap.Data
	return r.Update(ctx, found)
}

func (r *Neo4jEnterpriseClusterReconciler) createOrUpdateService(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster) error {
	// Create headless service for cluster discovery
	headlessService := resources.BuildHeadlessServiceForEnterprise(cluster)
	if err := r.createOrUpdateService(ctx, cluster, headlessService); err != nil {
		return fmt.Errorf("failed to reconcile headless service: %w", err)
	}

	// Create client service for external access
	clientService := resources.BuildClientServiceForEnterprise(cluster)
	if err := r.createOrUpdateService(ctx, cluster, clientService); err != nil {
		return fmt.Errorf("failed to reconcile client service: %w", err)
	}

	return nil
}

func (r *Neo4jEnterpriseClusterReconciler) createOrUpdateService(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, service *corev1.Service) error {
	found := &corev1.Service{}
	err := r.Get(ctx, types.NamespacedName{Name: service.Name, Namespace: service.Namespace}, found)
	if err != nil && errors.IsNotFound(err) {
		if err := ctrl.SetControllerReference(cluster, service, r.Scheme); err != nil {
			return err
		}
		return r.Create(ctx, service)
	} else if err != nil {
		return err
	}

	// Update service if needed
	found.Spec.Ports = service.Spec.Ports
	found.Spec.Selector = service.Spec.Selector
	return r.Update(ctx, found)
}

func (r *Neo4jEnterpriseClusterReconciler) createAdminSecretIfNotExists(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster) error {
	secret := resources.BuildSecretForEnterprise(cluster)

	found := &corev1.Secret{}
	err := r.Get(ctx, types.NamespacedName{Name: secret.Name, Namespace: secret.Namespace}, found)
	if err != nil && errors.IsNotFound(err) {
		if err := ctrl.SetControllerReference(cluster, secret, r.Scheme); err != nil {
			return err
		}
		return r.Create(ctx, secret)
	} else if err != nil {
		return err
	}

	// Update secret if needed
	found.Data = secret.Data
	return r.Update(ctx, found)
}

func (r *Neo4jEnterpriseClusterReconciler) createOrUpdateStatefulSet(ctx context.Context, cluster *neo4jv1alpha1.Neo4jEnterpriseCluster, sts *appsv1.StatefulSet) error {
	found := &appsv1.StatefulSet{}
	err := r.Get(ctx, types.NamespacedName{Name: sts.Name, Namespace: sts.Namespace}, found)
	if err != nil && errors.IsNotFound(err) {
		if err := ctrl.SetControllerReference(cluster, sts, r.Scheme); err != nil {
			return err
		}
		return r.Create(ctx, sts)
	} else if err != nil {
		return err
	}

	// Update StatefulSet if needed (careful with rolling updates)
	if r.statefulSetNeedsUpdate(found, sts) {
		found.Spec.Template = sts.Spec.Template
		found.Spec.Replicas = sts.Spec.Replicas
		return r.Update(ctx, found)
	}

	return nil
}

func (r *Neo4jEnterpriseClusterReconciler) statefulSetNeedsUpdate(found, desired *appsv1.StatefulSet) bool {
	// Compare StatefulSet specs to determine if update is needed
	return found.Spec.Template.Spec.Containers[0].Image != desired.Spec.Template.Spec.Containers[0].Image
}
